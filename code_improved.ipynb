{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HATE DETECTION : H2H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"random_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20d780bf2acc0bb9</td>\n",
       "      <td>In keeping with the Northern Ireland wikipedia...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0558f1dd8c98988d</td>\n",
       "      <td>The answer to that question has finally been f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5eb71f3a0d810d2c</td>\n",
       "      <td>. UR SUCH A FUCKING GEEK ASS MOFO! UR MOTHERS ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ccf66b8308935bfe</td>\n",
       "      <td>OK, I'll have a look over it and let you know ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6319df121dd73181</td>\n",
       "      <td>{unblock|Unblock me at once!}}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  20d780bf2acc0bb9  In keeping with the Northern Ireland wikipedia...      0   \n",
       "1  0558f1dd8c98988d  The answer to that question has finally been f...      0   \n",
       "2  5eb71f3a0d810d2c  . UR SUCH A FUCKING GEEK ASS MOFO! UR MOTHERS ...      1   \n",
       "3  ccf66b8308935bfe  OK, I'll have a look over it and let you know ...      0   \n",
       "4  6319df121dd73181                     {unblock|Unblock me at once!}}      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  target  \n",
       "0             0        0       0       0              0       0  \n",
       "1             0        0       0       0              0       0  \n",
       "2             1        1       0       1              0       1  \n",
       "3             0        0       0       0              0       0  \n",
       "4             0        0       0       0              0       0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['target'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20d780bf2acc0bb9</td>\n",
       "      <td>In keeping with the Northern Ireland wikipedia...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0558f1dd8c98988d</td>\n",
       "      <td>The answer to that question has finally been f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5eb71f3a0d810d2c</td>\n",
       "      <td>. UR SUCH A FUCKING GEEK ASS MOFO! UR MOTHERS ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ccf66b8308935bfe</td>\n",
       "      <td>OK, I'll have a look over it and let you know ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6319df121dd73181</td>\n",
       "      <td>{unblock|Unblock me at once!}}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  20d780bf2acc0bb9  In keeping with the Northern Ireland wikipedia...      0   \n",
       "1  0558f1dd8c98988d  The answer to that question has finally been f...      0   \n",
       "2  5eb71f3a0d810d2c  . UR SUCH A FUCKING GEEK ASS MOFO! UR MOTHERS ...      1   \n",
       "3  ccf66b8308935bfe  OK, I'll have a look over it and let you know ...      0   \n",
       "4  6319df121dd73181                     {unblock|Unblock me at once!}}      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             1        1       0       1              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 1., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([25000, 6])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install torch\n",
    "import torch\n",
    "import numpy as np\n",
    "Y = []\n",
    "for i in df.values:\n",
    "    Y.append(torch.tensor(np.array(i[2:],dtype = np.float32)))\n",
    "Y = torch.stack(Y) \n",
    "print(Y)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EMBEDDINGS OF TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "# !pip install sentence_transformers\n",
    "from sentence_transformers import SentenceTransformer \n",
    "model_sen = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = []\n",
    "# for i in tqdm(df[\"comment_text\"]):\n",
    "#     j = torch.tensor(model_sen.encode(i))\n",
    "#     X.append(j) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = torch.stack(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #saving the embeddings for future use\n",
    "# with open('X.pkl', 'wb') as f:\n",
    "#     pickle.dump(X, f) \n",
    "\n",
    "# print(\"Stacked tensor saved to stacked_tensor.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0064,  0.0095, -0.0159,  ..., -0.0303,  0.0116,  0.0360]],\n",
      "\n",
      "        [[ 0.0223, -0.0205,  0.0037,  ..., -0.0511, -0.0188,  0.0055]],\n",
      "\n",
      "        [[-0.0434,  0.0195, -0.0081,  ...,  0.0123, -0.0408, -0.0310]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0443,  0.0508, -0.0243,  ...,  0.0097,  0.0301, -0.0234]],\n",
      "\n",
      "        [[-0.0204,  0.0148,  0.0024,  ..., -0.0210, -0.0555,  0.0149]],\n",
      "\n",
      "        [[ 0.0763,  0.0464,  0.0062,  ..., -0.0104, -0.0767,  0.0558]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "\n",
    "# Load the embeddings from the pickle file\n",
    "with open('X.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "X = X.unsqueeze(1)\n",
    "# Print the loaded tensor\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25000, 1, 768])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combing X and Y to form a dataset\n",
    "# !pip install tensorflow\n",
    "import tensorflow as tf\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X,Y))\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(1000)\n",
    "dataset = dataset.batch(16)\n",
    "dataset = dataset.prefetch(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset.take(int(len(dataset)*.7))\n",
    "val = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))\n",
    "test = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 13:28:18.777527: W tensorflow/core/kernels/data/cache_dataset_ops.cc:914] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[ 0.08325461,  0.00196811,  0.0030059 , ...,  0.01355089,\n",
       "          -0.01876356, -0.01708327]],\n",
       " \n",
       "        [[ 0.02172103,  0.06832755, -0.00109624, ...,  0.05685737,\n",
       "          -0.05219594, -0.01677671]],\n",
       " \n",
       "        [[-0.02178163,  0.10040811,  0.01068756, ...,  0.00071513,\n",
       "          -0.01322643,  0.01048273]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-0.00512984,  0.03185592,  0.0106814 , ..., -0.00739371,\n",
       "           0.03378417, -0.01757451]],\n",
       " \n",
       "        [[ 0.05113736, -0.00228241,  0.01081558, ...,  0.05385644,\n",
       "          -0.0387287 , -0.01703592]],\n",
       " \n",
       "        [[ 0.09448456, -0.00915827, -0.01450976, ...,  0.05159661,\n",
       "          -0.0403772 ,  0.04093753]]], dtype=float32),\n",
       " array([[0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 1., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator = train.as_numpy_iterator()\n",
    "train_generator.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (\u001b[38;5;33mActivation\u001b[0m)       │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_7 (\u001b[38;5;33mActivation\u001b[0m)       │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_8 (\u001b[38;5;33mActivation\u001b[0m)       │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Activation\n",
    "import torch\n",
    "# Define the Keras model\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(768, activation = 'tanh')),\n",
    "    Dense(128),\n",
    "    Activation('relu'),\n",
    "    Dense(16),\n",
    "    Activation('tanh'),\n",
    "    Dense(6),\n",
    "    Activation('sigmoid')\n",
    "])\n",
    "# model1(X_text_train.unsqueeze(1))\n",
    "\n",
    "# Compile the model\n",
    "# optimizer = tf.keras.optimizers.Adam(lr=0.01)\n",
    "model.compile(loss='binary_crossentropy', optimizer= 'Adam')\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.1514"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 13:29:22.472221: W tensorflow/core/kernels/data/cache_dataset_ops.cc:914] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 38ms/step - loss: 0.1514 - val_loss: 0.0715\n",
      "Epoch 2/2\n",
      "\u001b[1m   3/1094\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m45s\u001b[0m 42ms/step - loss: 0.0707 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 13:29:24.308946: W tensorflow/core/kernels/data/cache_dataset_ops.cc:914] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1093/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0647"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 13:30:07.108112: W tensorflow/core/kernels/data/cache_dataset_ops.cc:914] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 40ms/step - loss: 0.0647 - val_loss: 0.0648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 13:30:08.605501: W tensorflow/core/kernels/data/cache_dataset_ops.cc:914] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, epochs = 2, validation_data= val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">9,443,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">196,736</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,064</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">102</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m)           │     \u001b[38;5;34m9,443,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m196,736\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m2,064\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_7 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m102\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_8 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,926,692</span> (110.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m28,926,692\u001b[0m (110.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,642,230</span> (36.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,642,230\u001b[0m (36.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,284,462</span> (73.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m19,284,462\u001b[0m (73.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 7.1044e-02,  4.8869e-02, -5.5874e-03,  4.4661e-03, -6.5701e-03,\n",
       "           3.8937e-02, -3.0229e-02,  4.2765e-02, -1.2309e-02,  1.3392e-02,\n",
       "           2.7514e-02,  2.2837e-02,  7.3720e-02,  5.7937e-02, -6.5132e-03,\n",
       "           6.2169e-03,  1.0437e-02, -5.4102e-03,  5.1908e-02, -2.3087e-02,\n",
       "          -5.3403e-03,  2.7886e-02, -6.2808e-03,  1.0456e-02,  1.0376e-02,\n",
       "           1.3865e-02,  5.3587e-02,  2.5933e-02, -3.4685e-03, -3.3729e-02,\n",
       "          -9.2243e-03, -4.4367e-02, -4.2160e-02,  2.2287e-02,  1.7971e-06,\n",
       "          -4.2737e-02,  6.8327e-02, -1.1885e-03, -5.4989e-02,  1.0131e-01,\n",
       "           4.8786e-03, -7.5937e-02, -2.4148e-02, -3.0298e-02,  1.2081e-02,\n",
       "          -2.1161e-02,  9.9956e-03,  2.6894e-02,  2.1409e-02, -5.1983e-03,\n",
       "          -8.0993e-03, -5.3718e-02,  2.8362e-02, -2.2426e-02,  7.7232e-03,\n",
       "           1.9633e-02,  1.5691e-02,  3.1930e-02, -1.3382e-02, -3.5782e-03,\n",
       "          -2.1913e-02, -7.3919e-03, -1.0127e-02,  4.6985e-02,  8.1480e-03,\n",
       "           1.1517e-03,  5.5867e-02,  4.1811e-02,  1.2018e-02,  4.4499e-02,\n",
       "          -5.5845e-02,  1.4369e-02, -1.4887e-02,  7.3567e-02, -2.5774e-02,\n",
       "          -6.4631e-02, -6.8582e-02,  1.1538e-02,  1.2647e-02,  1.6839e-02,\n",
       "          -4.2993e-02,  4.4433e-02, -2.6788e-03,  4.0687e-03, -9.6447e-04,\n",
       "           3.7081e-02,  2.7405e-02, -3.6995e-02,  3.1758e-02,  6.2195e-03,\n",
       "          -1.5648e-02, -1.1779e-02, -7.7671e-03,  4.8557e-02, -3.9057e-02,\n",
       "          -1.9254e-02, -2.9756e-02,  2.6490e-02,  2.6594e-02, -8.5102e-02,\n",
       "           2.2938e-02,  1.8611e-02,  6.1305e-02,  1.6736e-03,  2.0355e-02,\n",
       "          -4.5403e-02, -6.0973e-02, -3.5584e-02,  1.3550e-02, -2.2609e-02,\n",
       "          -2.9223e-02,  1.0343e-02,  7.2091e-02, -2.5133e-02,  4.9514e-02,\n",
       "           2.8878e-02, -1.0137e-02,  8.9613e-03,  7.2510e-03,  2.4166e-02,\n",
       "          -7.6513e-02,  2.6885e-02, -1.6210e-03,  2.1188e-02, -3.4250e-02,\n",
       "          -5.6322e-02,  5.5374e-03,  2.2914e-02, -7.5068e-02, -5.1325e-02,\n",
       "           2.5818e-02, -4.1814e-02,  9.4418e-04, -8.9229e-02,  5.0673e-03,\n",
       "           2.3107e-02,  2.7155e-02,  6.1924e-02,  3.6944e-02, -5.3907e-02,\n",
       "          -1.1159e-02, -5.9075e-02, -4.0690e-02, -1.1791e-02,  4.0260e-02,\n",
       "          -5.6875e-02, -1.7933e-02, -3.9005e-02, -6.9009e-03, -1.2087e-02,\n",
       "           5.5754e-02,  6.4322e-02,  6.0282e-02, -2.6912e-02, -2.1454e-02,\n",
       "           5.4590e-04, -1.7624e-02, -2.7487e-02, -4.0936e-02,  1.3322e-02,\n",
       "           4.4038e-02,  5.3974e-02,  4.0881e-02, -1.6505e-03, -2.5372e-02,\n",
       "           2.0101e-02,  2.8136e-02, -1.0794e-02, -4.3493e-03,  2.3900e-02,\n",
       "          -3.6270e-02,  3.0059e-02, -2.0056e-02, -1.1372e-01,  3.4602e-02,\n",
       "          -8.0011e-03, -2.3971e-02,  2.0648e-02,  3.8264e-02,  1.1389e-02,\n",
       "          -7.0750e-02, -9.0861e-02, -2.3234e-02,  1.0858e-02, -5.8890e-02,\n",
       "           1.8015e-02,  3.1650e-02, -2.4400e-02, -1.0695e-02, -2.2094e-02,\n",
       "          -3.4491e-02,  2.4458e-02,  2.0260e-03,  7.8228e-03,  9.8664e-03,\n",
       "          -6.3189e-02,  5.4372e-02, -1.9645e-02, -5.4128e-02, -3.2479e-03,\n",
       "          -8.5361e-03,  5.1805e-02, -6.5996e-03,  4.4311e-02,  2.5256e-02,\n",
       "          -2.7668e-04,  2.0129e-02, -3.9993e-02,  4.6922e-03, -4.0948e-03,\n",
       "           1.7867e-02, -4.0203e-03,  7.2425e-02,  7.6368e-02, -8.3126e-03,\n",
       "           4.6697e-03, -2.8625e-02, -3.2147e-02,  2.7285e-02,  3.3850e-02,\n",
       "          -2.8935e-02, -2.0012e-02, -3.3662e-02,  2.7715e-02,  2.9784e-03,\n",
       "          -4.9005e-02,  1.5040e-03, -2.7293e-03,  2.2535e-02, -2.5651e-03,\n",
       "           2.2226e-02, -2.3007e-02, -1.2039e-02,  4.5878e-03,  1.0627e-02,\n",
       "           3.5049e-02,  4.6634e-02, -3.9181e-02, -5.9034e-03, -7.5558e-02,\n",
       "           4.6565e-02,  3.0319e-02, -3.6979e-02,  1.8152e-02, -3.0330e-02,\n",
       "          -3.3780e-02, -1.7170e-02,  6.9327e-03, -1.8003e-02, -1.9764e-02,\n",
       "           7.2542e-03,  4.7363e-03, -2.8908e-02, -3.5749e-02,  1.1670e-02,\n",
       "           2.1844e-04, -1.6462e-02,  4.2370e-02, -2.6716e-02, -4.4089e-02,\n",
       "          -2.2901e-02, -8.3355e-02, -3.5057e-02,  8.5336e-04, -3.1510e-02,\n",
       "           2.8141e-02,  9.7187e-03,  1.1350e-02,  5.2947e-02, -2.0796e-02,\n",
       "          -1.7681e-02, -1.7682e-02,  3.4609e-03,  1.3523e-02,  3.5680e-02,\n",
       "           2.0880e-02, -2.7505e-02, -3.8143e-02, -1.6243e-02, -1.8885e-02,\n",
       "           3.4330e-02,  1.0150e-02,  2.7546e-02,  2.9039e-02, -3.1139e-03,\n",
       "           5.2377e-02,  4.1625e-03,  8.1275e-03,  3.8966e-02, -2.9989e-02,\n",
       "           2.0031e-02,  3.5375e-02,  1.1353e-02, -1.9067e-02,  1.6692e-03,\n",
       "           4.9613e-04, -3.6605e-02, -6.6361e-02,  2.8803e-03, -2.9052e-03,\n",
       "          -2.9233e-02,  1.9262e-03,  1.1862e-03,  9.9035e-03,  1.6134e-02,\n",
       "           3.0653e-02, -4.9778e-02, -4.0296e-02, -2.9820e-02,  4.2565e-02,\n",
       "           4.4566e-02,  2.7248e-02, -4.6262e-03, -1.3610e-02, -1.2801e-02,\n",
       "          -1.2405e-02,  1.5648e-02, -3.0673e-02,  4.4440e-02, -1.6699e-02,\n",
       "           2.4837e-02,  2.6210e-02,  3.8244e-02, -5.4068e-02,  7.1430e-03,\n",
       "           4.8267e-02,  3.1220e-02,  3.4704e-02, -6.0913e-04, -3.5255e-02,\n",
       "          -5.1657e-03,  8.7187e-03,  4.6782e-02,  4.8580e-02, -1.5867e-02,\n",
       "          -6.8580e-03,  3.1987e-02, -5.0833e-02, -7.6475e-02,  8.1336e-02,\n",
       "           1.5198e-02,  3.3952e-02, -4.5120e-02,  1.3479e-02, -1.0163e-01,\n",
       "          -4.0827e-02, -3.6467e-02, -4.6948e-02,  2.7728e-02, -1.1397e-02,\n",
       "          -4.0699e-02, -5.4641e-02, -3.7623e-03, -3.8196e-02,  6.3660e-03,\n",
       "           2.5791e-02, -5.0941e-02,  1.4480e-02,  2.4899e-02, -3.6357e-03,\n",
       "          -2.3681e-02, -4.5860e-02, -3.2173e-02, -2.7983e-03, -1.5769e-02,\n",
       "           2.9884e-02,  6.1169e-03,  4.4095e-03,  2.1788e-02, -5.3488e-02,\n",
       "          -8.9913e-03,  2.5116e-02,  9.5560e-03,  9.3016e-02,  1.7587e-02,\n",
       "           2.3541e-02, -1.9538e-02, -7.6306e-03,  7.5641e-03, -1.0566e-03,\n",
       "          -1.0367e-02, -4.5442e-02, -3.6126e-03, -5.7619e-02, -3.7534e-02,\n",
       "          -2.8856e-02, -2.0417e-02, -1.4671e-02, -8.1673e-02, -4.8586e-03,\n",
       "           2.6010e-02, -5.2849e-02,  4.0262e-02,  5.5416e-02,  9.8809e-03,\n",
       "          -4.0901e-02, -9.2166e-03,  2.8101e-02, -5.0303e-02, -3.3373e-02,\n",
       "          -1.0483e-02,  4.1095e-02,  2.1566e-02,  3.5669e-02, -2.0567e-02,\n",
       "           1.6683e-02,  5.8564e-02,  4.0466e-02, -8.5777e-02, -5.7507e-02,\n",
       "          -3.8602e-02, -2.2768e-02, -2.3510e-02, -2.9716e-03, -6.0900e-02,\n",
       "          -1.0362e-02,  1.2397e-02, -3.3431e-02,  1.2839e-03,  2.5268e-03,\n",
       "          -2.7102e-02,  2.5044e-03, -2.8483e-02, -4.1577e-02, -3.9597e-02,\n",
       "           4.1135e-03,  9.9247e-02, -5.0776e-02,  5.6999e-02, -1.0393e-03,\n",
       "          -4.0718e-02,  1.0212e-02,  2.9000e-02,  2.3362e-03, -9.5376e-02,\n",
       "          -7.5528e-02,  1.0756e-02,  2.9507e-02,  1.6654e-02, -2.7495e-02,\n",
       "          -3.1134e-03,  2.0931e-03,  2.0237e-02,  2.2890e-02,  6.8417e-02,\n",
       "          -3.2733e-02,  2.8659e-02, -5.2309e-03, -8.1720e-02,  1.0824e-02,\n",
       "          -5.3866e-03, -3.8473e-02, -3.6378e-03,  7.9328e-03,  3.8340e-02,\n",
       "          -3.9983e-02,  3.0401e-02, -5.5960e-02, -1.7855e-02, -1.2376e-02,\n",
       "           7.7073e-02,  2.9610e-02,  4.9911e-02, -2.0249e-02, -1.5894e-02,\n",
       "           1.1536e-03, -2.1318e-02,  3.3072e-03,  4.6566e-02, -3.7400e-02,\n",
       "          -5.7889e-02,  1.3297e-02, -6.0553e-02, -1.0347e-02,  5.9476e-02,\n",
       "           5.4980e-02,  4.4616e-02, -5.0700e-02,  9.5456e-03,  2.6119e-02,\n",
       "          -2.4961e-03,  9.1370e-03, -2.2744e-02, -2.9625e-02,  1.2221e-02,\n",
       "           1.7907e-02,  4.9233e-02,  9.6378e-05,  2.3772e-02, -5.3830e-04,\n",
       "          -4.8940e-02,  1.9729e-02, -1.1565e-02, -1.3691e-02, -6.8058e-02,\n",
       "          -2.4462e-02, -1.0935e-02, -9.8635e-02,  5.4593e-02, -2.0980e-02,\n",
       "           8.8961e-02,  5.1376e-02, -2.9989e-02,  1.0046e-01,  1.9196e-02,\n",
       "          -2.3795e-03, -1.3035e-02, -2.6390e-02, -2.3671e-02,  6.4556e-03,\n",
       "           2.4363e-02,  3.0615e-02, -5.5872e-02, -6.7855e-02, -3.3303e-03,\n",
       "           5.5931e-03, -6.4083e-02, -1.4342e-02, -4.8057e-02, -7.3419e-02,\n",
       "          -4.7730e-03, -5.6001e-02,  2.0299e-03, -3.0443e-02,  4.0567e-03,\n",
       "          -1.7366e-03,  2.1123e-02, -3.4391e-02,  7.3512e-02,  4.4751e-03,\n",
       "           2.0701e-02,  4.3402e-02,  6.5022e-02,  7.8028e-02,  4.3374e-03,\n",
       "           2.6909e-02, -1.1314e-02,  5.8024e-02, -1.4898e-02, -5.0592e-03,\n",
       "           1.0594e-02,  1.7893e-02,  2.4891e-02, -1.2353e-02,  5.0281e-02,\n",
       "          -5.0981e-03,  1.0807e-03,  1.3344e-02,  3.8475e-02, -1.0626e-02,\n",
       "           1.9866e-02,  7.3963e-02, -8.6036e-03, -1.0940e-01, -3.0279e-02,\n",
       "          -6.7467e-33, -3.3228e-02,  4.9212e-02,  8.9559e-03,  8.5152e-02,\n",
       "          -1.0722e-02, -9.8300e-04,  2.6135e-02, -1.1605e-02,  7.0307e-03,\n",
       "          -2.4762e-02,  1.3759e-02, -2.6246e-03,  2.6141e-02,  2.8948e-03,\n",
       "          -2.7230e-02, -4.7578e-04,  3.1011e-02,  5.7954e-02, -1.3017e-03,\n",
       "          -1.7687e-02,  7.8851e-03, -1.1807e-02,  7.5036e-03,  8.7246e-02,\n",
       "           1.4597e-02,  2.3685e-02, -1.9747e-02,  1.0499e-02,  3.1775e-02,\n",
       "           5.3620e-02, -9.5991e-03,  2.0918e-03, -1.8965e-02,  6.3869e-02,\n",
       "           2.3895e-03,  5.6108e-02, -4.3004e-02, -2.5770e-03, -2.0825e-02,\n",
       "           4.3113e-02, -2.3896e-03, -3.5614e-02,  3.6784e-02, -1.2158e-02,\n",
       "          -5.8968e-02, -5.3262e-02,  5.4344e-02, -2.4000e-03, -5.1210e-02,\n",
       "           1.9003e-02, -4.9180e-02, -2.9508e-03, -3.2268e-02, -6.0625e-02,\n",
       "           4.8747e-03,  1.9861e-02,  4.0974e-02,  3.5378e-03, -8.2119e-03,\n",
       "           1.7862e-02, -3.1354e-03, -1.2039e-02, -1.9407e-02, -9.7043e-03,\n",
       "           6.9941e-02,  4.8728e-04, -1.0538e-02,  2.6149e-02,  1.3728e-02,\n",
       "           4.9172e-02, -2.8931e-02,  5.5526e-02, -1.8570e-02, -2.1690e-02,\n",
       "          -6.3198e-03, -4.1819e-02,  3.7547e-02,  7.9036e-02,  6.0668e-02,\n",
       "           6.2642e-02,  5.3814e-03,  8.6408e-03, -2.6631e-02, -1.4921e-02,\n",
       "           3.7365e-02,  3.0654e-02,  3.1639e-03,  1.9966e-02, -3.6101e-02,\n",
       "          -5.4137e-02,  2.0506e-02, -3.4889e-02,  1.8764e-02, -5.6949e-02,\n",
       "           3.6146e-02, -2.6938e-02,  2.5580e-02, -1.0225e-02,  3.2216e-02,\n",
       "           1.4250e-02,  1.1221e-01,  6.4644e-02, -3.3194e-02, -1.0911e-02,\n",
       "           2.0233e-02, -2.8400e-03,  1.3348e-02,  3.4529e-02, -6.4580e-03,\n",
       "          -3.4298e-02, -2.7282e-02, -3.1160e-03,  2.5108e-03, -1.9498e-02,\n",
       "          -3.8542e-02,  1.0328e-03,  6.3110e-03, -5.8976e-03,  1.0079e-02,\n",
       "          -2.3699e-02, -6.7959e-03, -1.6790e-02, -6.9547e-02, -1.0431e-02,\n",
       "           6.3094e-03,  1.0624e-03, -1.8533e-02,  2.9104e-03, -4.9349e-02,\n",
       "          -4.9128e-02, -3.4939e-02, -3.5187e-03,  2.5307e-07, -3.1426e-02,\n",
       "           2.3320e-02, -8.4771e-03,  4.7985e-02,  1.0720e-03,  2.6220e-02,\n",
       "          -4.4028e-02,  3.0689e-02, -1.1038e-01,  2.1775e-02, -1.0757e-02,\n",
       "          -1.2845e-02,  2.7056e-02,  3.7800e-02, -5.8524e-02,  4.0233e-02,\n",
       "          -3.0754e-02, -4.1449e-02, -1.1084e-02, -5.9965e-02, -4.4199e-02,\n",
       "          -2.8099e-02,  6.4059e-02, -3.5725e-03,  3.6490e-02,  5.4105e-02,\n",
       "          -4.0773e-02,  5.5371e-03,  7.2936e-02,  1.4622e-02,  2.2693e-04,\n",
       "          -7.5496e-04,  1.5652e-02,  4.7987e-02,  1.0639e-02, -8.7449e-02,\n",
       "           5.1130e-03,  1.2478e-02,  1.3239e-02, -1.5039e-02,  1.2901e-02,\n",
       "          -6.9832e-02,  1.4222e-02,  5.1344e-03,  5.3232e-02,  2.3555e-02,\n",
       "           3.4489e-02,  2.4840e-02, -5.5570e-02, -6.5067e-03, -5.2332e-02,\n",
       "          -4.1305e-02,  5.7339e-03, -1.1027e-02, -1.5855e-02, -2.9469e-02,\n",
       "           1.7083e-02, -7.8417e-03,  5.6922e-02, -4.5311e-03,  3.9485e-02,\n",
       "          -4.7610e-02,  2.9032e-03,  9.6862e-02,  1.4223e-02, -9.5500e-03,\n",
       "           1.4201e-02,  4.4643e-35,  3.1372e-02, -1.0509e-02,  1.1341e-02,\n",
       "           3.2382e-02,  1.4097e-02,  1.8568e-02, -3.5674e-02,  3.9804e-02,\n",
       "           2.3215e-02, -1.1729e-02,  2.9804e-02]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = torch.tensor(model_sen.encode(\"I'll kill you\")).unsqueeze(0).unsqueeze(0)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x13c47a2a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6332574 , 0.01883683, 0.15989828, 0.05047224, 0.14624305,\n",
       "        0.11661158]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test = model.predict(X_test)\n",
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
       "       'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 13:30:33.075489: W tensorflow/core/kernels/data/cache_dataset_ops.cc:914] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "test_batch_X, test_batch_Y = test.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_Y = (model.predict(test_batch_X) > 0.20).astype(int)\n",
    "predict_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 1., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALUATING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9583333333333334\n",
      "recall:  0.5714285714285714\n",
      "precision:  0.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision = precision_score(test_batch_Y, predict_Y, average='micro')\n",
    "recall = recall_score(test_batch_Y, predict_Y, average= 'micro')\n",
    "accuracy = (predict_Y == test_batch_Y).astype(float).mean().item()\n",
    "print(\"accuracy: \",accuracy) \n",
    "print(\"recall: \",recall)\n",
    "print(\"precision: \",precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "save_model(model, 'hate_detection.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "model = load_model('hate_detection.keras') \n",
    "\n",
    "# Now you can use the loaded_model for predictions or further training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_hate(tweet):\n",
    "    eval_X = torch.tensor(model_sen.encode(tweet)).unsqueeze(0).unsqueeze(0)\n",
    "    res = model.predict(eval_X)\n",
    "    result = f'tweet: \"{tweet}\"\\n'\n",
    "    for i, col in enumerate(df.columns[2:]):\n",
    "        result += f'{col}: {res[0][i]>0.5}\\n'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WELCOME TO HATE DETECTOR: H2H\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "tweet: \"You are a very dumb guy\"\n",
      "toxic: True\n",
      "severe_toxic: False\n",
      "obscene: False\n",
      "threat: False\n",
      "insult: False\n",
      "identity_hate: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"WELCOME TO HATE DETECTOR: H2H\")\n",
    "tweet = input(\"Enter the tweet to check\")\n",
    "print(evaluate_hate(tweet)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
